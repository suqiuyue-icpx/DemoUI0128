# csv_toolkit.py
import csv

import pandas as pd
import chardet
import os
import re

import yaml
from tabulate import tabulate


class CSVToolkit:
	"""CSVæ–‡ä»¶å¤„ç†å·¥å…·åŒ…"""

	@staticmethod
	def detect_encoding(file_path):
		"""æ£€æµ‹æ–‡ä»¶ç¼–ç """
		with open(file_path, 'rb') as f:
			result = chardet.detect(f.read())
		return result['encoding']

	@staticmethod
	def read_csv_smart(file_path, **kwargs):
		"""æ™ºèƒ½è¯»å–CSVæ–‡ä»¶"""
		# è‡ªåŠ¨æ£€æµ‹ç¼–ç 
		encoding = kwargs.pop('encoding', None)
		if encoding is None:
			encoding = CSVToolkit.detect_encoding(file_path)

		# è¯»å–æ–‡ä»¶
		return pd.read_csv(file_path, encoding=encoding, **kwargs)

	@staticmethod
	def preview_csv(file_path, n_rows=10):
		"""é¢„è§ˆCSVæ–‡ä»¶"""
		df = CSVToolkit.read_csv_smart(file_path, nrows=n_rows)

		print(f"æ–‡ä»¶: {file_path}")
		print(f"ç¼–ç : {CSVToolkit.detect_encoding(file_path)}")
		print(f"å¤§å°: {os.path.getsize(file_path) / 1024:.2f} KB")
		print(f"è¡Œæ•°: æœªçŸ¥ï¼ˆé¢„è§ˆå‰{n_rows}è¡Œï¼‰")
		print(f"åˆ—æ•°: {len(df.columns)}")
		print("\nåˆ—å:")
		for i, col in enumerate(df.columns, 1):
			print(f"  {i:2d}. {col}")

		print(f"\nå‰{n_rows}è¡Œæ•°æ®:")
		print(tabulate(df, headers='keys', tablefmt='grid', showindex=False))

		return df

	@staticmethod
	def validate_csv(file_path):
		"""éªŒè¯CSVæ–‡ä»¶"""
		try:
			df = CSVToolkit.read_csv_smart(file_path)

			issues = []
			# æ£€æŸ¥ç©ºå€¼
			null_counts = df.isnull().sum()
			if null_counts.any():
				issues.append(f"å­˜åœ¨ç©ºå€¼: {null_counts[null_counts > 0].to_dict()}")

			# æ£€æŸ¥é‡å¤è¡Œ
			duplicates = df.duplicated().sum()
			if duplicates > 0:
				issues.append(f"å­˜åœ¨ {duplicates} è¡Œé‡å¤æ•°æ®")

			# æ£€æŸ¥æ•°æ®ç±»å‹
			dtypes = df.dtypes.astype(str).to_dict()

			return {
				'valid': len(issues) == 0,
				'issues': issues,
				'stats': {
					'rows': len(df),
					'columns': len(df.columns),
					'size_kb': os.path.getsize(file_path) / 1024,
					'dtypes': dtypes
				}
			}

		except Exception as e:
			return {
				'valid': False,
				'issues': [f"è¯»å–å¤±è´¥: {str(e)}"],
				'stats': {}
			}

	@staticmethod
	def convert_encoding(file_path, target_encoding='utf-8'):
		"""è½¬æ¢æ–‡ä»¶ç¼–ç """
		# æ£€æµ‹å½“å‰ç¼–ç 
		current_encoding = CSVToolkit.detect_encoding(file_path)

		if current_encoding.lower() == target_encoding.lower():
			#æ‰“å°å†…å®¹å¤ªå¤šäº†ï¼Œæš‚æ—¶æ³¨é‡Š
			#print(f"æ–‡ä»¶å·²ç»æ˜¯ {target_encoding} ç¼–ç ")
			return

		# è¯»å–å¹¶é‡æ–°ä¿å­˜
		df = pd.read_csv(file_path, encoding=current_encoding)

		# å¤‡ä»½åŸæ–‡ä»¶
		backup_path = file_path + '.bak'
		os.rename(file_path, backup_path)

		# ä¿å­˜ä¸ºæ–°ç¼–ç 
		df.to_csv(file_path, encoding=target_encoding, index=False)

		print(f"å·²å°†æ–‡ä»¶ä» {current_encoding} è½¬æ¢ä¸º {target_encoding}")
		print(f"åŸæ–‡ä»¶å·²å¤‡ä»½ä¸º: {backup_path}")

	@staticmethod
	def _format_yaml_value(value: str) -> str:
		"""æ ¼å¼åŒ–YAMLå€¼ï¼Œå¤„ç†ç‰¹æ®Šå­—ç¬¦"""
		if not value:
			return ""

		# ç‰¹æ®Šå­—ç¬¦åˆ—è¡¨
		special_chars = [':', '[', ']', '{', '}', '&', '*', '?', '|', '-', '>', '%', '@', '`', '#']

		# æ£€æŸ¥æ˜¯å¦éœ€è¦å¼•å·
		needs_quotes = False
		for char in special_chars:
			if char in value:
				needs_quotes = True
				break

		# æ£€æŸ¥æ˜¯å¦åŒ…å«ç©ºæ ¼
		if ' ' in value or '\t' in value:
			needs_quotes = True

		# å¦‚æœæ˜¯ç©ºå­—ç¬¦ä¸²æˆ–åªåŒ…å«ç©ºæ ¼
		if not value.strip():
			return '""'

		# å¤„ç†å¸ƒå°”å€¼å’Œæ•°å­—
		if value.lower() in ['true', 'false']:
			return value.lower()
		elif value.isdigit():
			return value

		if needs_quotes:
			# è½¬ä¹‰åŒå¼•å·
			escaped_value = value.replace('"', '\\"')
			return f'"{escaped_value}"'
		else:
			return value

	@staticmethod
	def csv_to_yamldata_code(csv_file_path, yaml_output_path):
		"""
		å°†ç‰¹å®šæ ¼å¼çš„CSVæ–‡ä»¶è½¬æ¢ä¸ºæŒ‡å®šçš„YAMLæ ¼å¼
		CSVæ ¼å¼: id,detail,data,check,screenshot
		dataå­—æ®µæ ¼å¼: "key1:value1;key2:value2"

		è½¬æ¢ä¸ºYAMLæ ¼å¼:
		- id: xxx
		  detail: xxx
		  screenshot: xxx
		  data:
		    key1: value1
		    key2: value2
		  check:
		    - xxx
		"""

		# è¯»å–CSVæ–‡ä»¶
		df = pd.read_csv(csv_file_path)

		# æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
		required_columns = ['id', 'detail', 'data', 'check', 'screenshot']
		for col in required_columns:
			if col not in df.columns:
				raise ValueError(f"CSVæ–‡ä»¶ä¸­ç¼ºå°‘å¿…è¦çš„åˆ—: {col}")

		# ç”ŸæˆYAMLå­—ç¬¦ä¸²
		yaml_lines = []

		for index, row in df.iterrows():
			# è·å–åŸºç¡€å­—æ®µ
			test_id = str(row['id']).strip()
			detail = str(row['detail']).strip()
			screenshot = str(row['screenshot']).strip()

			# è§£ædataå­—æ®µ (æ ¼å¼: "username:test1;password:A1")
			data_str = str(row['data']).strip()
			data_dict = {}

			if data_str and data_str != 'nan':
				# æŒ‰åˆ†å·åˆ†å‰²é”®å€¼å¯¹
				pairs = [pair.strip() for pair in data_str.split(';') if pair.strip()]

				for pair in pairs:
					if ':' in pair:
						# æŒ‰ç¬¬ä¸€ä¸ªå†’å·åˆ†å‰²
						key_value = pair.split(':', 1)
						if len(key_value) == 2:
							key = key_value[0].strip()
							value = key_value[1].strip()

							# æ¸…ç†valueï¼ˆå»é™¤å¯èƒ½çš„å¼•å·ï¼‰
							value = value.strip('"\'')

							# æ·»åŠ åˆ°å­—å…¸
							data_dict[key] = value

			# è§£æcheckå­—æ®µ
			check_str = str(row['check']).strip()
			check_list = []

			if check_str and check_str != 'nan':
				# æŒ‰é€—å·åˆ†å‰²å¤šä¸ªæ£€æŸ¥é¡¹
				check_items = [item.strip() for item in check_str.split(';') if item.strip()]
				check_list = check_items

			# ç”ŸæˆYAMLæ¡ç›®
			yaml_lines.append(f"- id : {test_id}")
			yaml_lines.append(f"  detail : {detail}")

			# æ ¹æ®ä½ çš„éœ€æ±‚ï¼Œä½¿ç”¨å›ºå®šçš„screenshotå€¼æˆ–ä»CSVè¯»å–
			# è¿™é‡Œä½¿ç”¨å›ºå®šçš„å€¼ "username_pawd_success"
			# yaml_lines.append(f"  screenshot : username_pawd_success")
			# å¦‚æœè¦ç”¨CSVä¸­çš„å€¼ï¼Œç”¨ä¸‹é¢è¿™è¡Œï¼š
			yaml_lines.append(f"  screenshot : {screenshot}")

			# æ·»åŠ dataéƒ¨åˆ†
			yaml_lines.append(f"  data :")

			if data_dict:
				for key, value in data_dict.items():
					yaml_lines.append(f"    {key} : {value}")
			else:
				yaml_lines.append(f"    # æ— dataå‚æ•°")

			# æ·»åŠ checkéƒ¨åˆ†
			yaml_lines.append(f"  check :")

			if check_list:
				for check_item in check_list:
					yaml_lines.append(f"    - {check_item}")
			else:
				yaml_lines.append(f"    - ''")

			# # åœ¨æ¯ä¸ªæµ‹è¯•ç”¨ä¾‹ä¹‹é—´æ·»åŠ ç©ºè¡Œï¼ˆé™¤äº†æœ€åä¸€ä¸ªï¼‰
			# if index < len(df) - 1:
			# 	yaml_lines.append("")

		# ç»„åˆæ‰€æœ‰è¡Œ
		yaml_content = "\n".join(yaml_lines)

		# ç¡®å®šè¾“å‡ºæ–‡ä»¶è·¯å¾„
		if yaml_output_path is None:
			# é»˜è®¤ä½¿ç”¨åŒç›®å½•ä¸‹çš„åŒåyamlæ–‡ä»¶
			base_name = os.path.splitext(csv_file_path)[0]
			yaml_output_path = base_name + '.yaml'

		# å†™å…¥æ–‡ä»¶
		with open(yaml_output_path, 'w', encoding='utf-8') as f:
			f.write(yaml_content)

		# æ‰“å°æ—¥å¿—å¤ªå¤šäº†ï¼Œæš‚æ—¶æ³¨é‡Š
		# print(f"âœ… YAMLæ–‡ä»¶å·²ç”Ÿæˆ: {yaml_output_path}")
		# print(f"ğŸ“Š è½¬æ¢äº† {len(df)} æ¡æµ‹è¯•ç”¨ä¾‹")

		# é¢„è§ˆç»“æœ
		# print("\nğŸ“ ç”Ÿæˆçš„YAMLå†…å®¹é¢„è§ˆ:")
		# print("=" * 50)
		# print(yaml_content)

		return yaml_content

	@staticmethod
	def csv_to_yamlelement_code(csv_file_path , yaml_output_path):
		"""
		    è§£æå¤æ‚æ ¼å¼çš„CSVæ–‡ä»¶å¹¶è½¬æ¢ä¸ºæŒ‡å®šçš„YAMLæ ¼å¼

		    CSVç»“æ„è¯´æ˜:
		    - ç¬¬ä¸€è¡Œ: åˆ—æ ‡é¢˜ï¼ˆåŒ…å«testinfo, testcase, checkç­‰ï¼‰
		    - ç¬¬äºŒè¡Œ: å­æ ‡é¢˜
		    - åç»­è¡Œ: æ•°æ®

		    è½¬æ¢ä¸ºYAMLæ ¼å¼:
		    testinfo:
		      - id: xxx
		        title: xxx
		        info: xxx
		    testcase:
		      - element_info: xxx
		        find_type: xxx
		        operate_type: xxx
		        info: xxx
		    check:
		      - element_info: xxx
		        find_type: xxx
		        info: xxx
		    """

		if not os.path.exists(csv_file_path):
			raise FileNotFoundError(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_file_path}")

		# è¯»å–CSVæ–‡ä»¶
		with open(csv_file_path, 'r', encoding='utf-8') as f:
			reader = csv.reader(f)
			rows = list(reader)

		if len(rows) < 2:
			raise ValueError("CSVæ–‡ä»¶è‡³å°‘éœ€è¦2è¡Œæ•°æ®ï¼ˆæ ‡é¢˜è¡Œå’Œå­æ ‡é¢˜è¡Œï¼‰")

		# è§£æåˆ—ç»“æ„
		header_row1 = rows[0]  # ç¬¬ä¸€è¡Œæ ‡é¢˜
		header_row2 = rows[1]  # ç¬¬äºŒè¡Œå­æ ‡é¢˜

		# æ‰¾å‡ºå„ä¸ªåŒºåŸŸçš„åˆ—ç´¢å¼•
		yaml_data = {
			'testinfo': [],
			'testcase': [],
			'check': []
		}

		# è§£ætestinfoåŒºåŸŸï¼ˆç¬¬0-3åˆ—ï¼‰
		# testinfo_start = 0
		# testinfo_columns = 4   æ ¹æ®ä½ çš„æ•°æ®ï¼Œtestinfoæœ‰4åˆ—ï¼Œåªå–å‰3åˆ—ä¿¡æ¯å³å¯

		for i in range(2, len(rows)):
			row = rows[i]

			# è·³è¿‡ç©ºè¡Œ
			if not any(cell and str(cell).strip() for cell in row):
				continue

			# æå–testinfoæ•°æ®
			if row[0]:  # idä¸ä¸ºç©º
				testinfo_item = {
					'id': row[0].strip(),
					'title': row[1].strip() if len(row) > 1 and row[1] else '',
					'info': row[2].strip() if len(row) > 2 and row[2] else ''
				}

				# åªæ·»åŠ éç©ºçš„æ•°æ®
				if any(testinfo_item.values()):
					yaml_data['testinfo'].append(testinfo_item)

		# è§£ætestcaseåŒºåŸŸï¼ˆç¬¬4-9åˆ—ï¼‰
		# æ ¹æ®ä½ çš„æ•°æ®ï¼Œtestcaseåœ¨row[4]åˆ°row[9]
		# testcase_fields = ['element_info', 'find_type', 'operate_type', 'info', 'index', 'element_name']

		for i in range(2, len(rows)):
			row = rows[i]

			# è·³è¿‡ç©ºè¡Œ
			if not any(cell and str(cell).strip() for cell in row):
				continue

			# æ£€æŸ¥æ˜¯å¦æœ‰testcaseæ•°æ®ï¼ˆç¬¬3åˆ—ä¸ä¸ºç©ºï¼‰
			if len(row) > 4 and row[4]:
				testcase_item = {
					'element_info': row[4].strip() if len(row) > 4 and row[4] else '',
					'find_type': row[5].strip() if len(row) > 5 and row[5] else '',
					'operate_type': row[6].strip() if len(row) > 6 and row[6] else '',
					'info': row[7].strip() if len(row) > 7 and row[7] else '',
					'index': row[8].strip() if len(row) > 8 and row[8] else '',
					'element_name': row[9].strip() if len(row) > 9 and row[9] else ''
				}

				# åªæ·»åŠ éç©ºçš„æ•°æ®
				if any(testcase_item.values()):
					yaml_data['testcase'].append(testcase_item)

		# è§£æcheckåŒºåŸŸï¼ˆç¬¬10-13åˆ—ï¼‰
		# check_fields = ['element_info', 'find_type', 'info', 'element_name']

		for i in range(2, len(rows)):
			row = rows[i]

			# è·³è¿‡ç©ºè¡Œ
			if not any(cell and str(cell).strip() for cell in row):
				continue

			# æ£€æŸ¥æ˜¯å¦æœ‰checkæ•°æ®ï¼ˆç¬¬8åˆ—ä¸ä¸ºç©ºï¼‰
			if len(row) > 8 and row[8]:
				check_item = {
					'element_info': row[10].strip() if len(row) > 10 and row[10] else '',
					'find_type': row[11].strip() if len(row) > 11 and row[11] else '',
					'info': row[12].strip() if len(row) > 12 and row[12] else '',
					'element_name': row[13].strip() if len(row) > 13 and row[13] else ''
				}

				# åªæ·»åŠ éç©ºçš„æ•°æ®
				if any(check_item.values()):
					yaml_data['check'].append(check_item)

		# å¦‚æœæ²¡æœ‰æŒ‡å®šè¾“å‡ºè·¯å¾„ï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
		if yaml_output_path is None:
			base_name = os.path.splitext(csv_file_path)[0]
			yaml_output_path = base_name + '.yaml'

		# å†™å…¥YAMLæ–‡ä»¶
		with open(yaml_output_path, 'w', encoding='utf-8') as f:
			# å†™å…¥testinfoéƒ¨åˆ†
			if yaml_data.get('testinfo'):
				f.write("testinfo:\n")
				for item in yaml_data['testinfo']:
					f.write("    - id: " + CSVToolkit._format_yaml_value(item.get('id', '')) + "\n")
					f.write("      title: " + CSVToolkit._format_yaml_value(item.get('title', '')) + "\n")
					f.write("      info: " + CSVToolkit._format_yaml_value(item.get('info', '')) + "\n")
				f.write("\n")  # ç©ºè¡Œåˆ†éš”

			# å†™å…¥testcaseéƒ¨åˆ†
			if yaml_data.get('testcase'):
				f.write("testcase:\n")
				for i, item in enumerate(yaml_data['testcase']):
					if i > 0:
						f.write("\n")  # åœ¨æ¯ä¸ªtestcaseé¡¹ä¹‹é—´æ·»åŠ ç©ºè¡Œ

					f.write("    - element_info: " + CSVToolkit._format_yaml_value(
						item.get('element_info', '')) + "\n")
					f.write(
						"      find_type: " + CSVToolkit._format_yaml_value(item.get('find_type', '')) + "\n")
					f.write("      operate_type: " + CSVToolkit._format_yaml_value(
						item.get('operate_type', '')) + "\n")
					f.write("      info: " + CSVToolkit._format_yaml_value(item.get('info', '')) + "\n")
					f.write("      index: " + CSVToolkit._format_yaml_value(item.get('index', '')) + "\n")
				f.write("\n")  # ç©ºè¡Œåˆ†éš”

			# å†™å…¥checkéƒ¨åˆ†
			if yaml_data.get('check'):
				f.write("check:\n")
				for i, item in enumerate(yaml_data['check']):
					if i > 0:
						f.write("\n")  # åœ¨æ¯ä¸ªchecké¡¹ä¹‹é—´æ·»åŠ ç©ºè¡Œ

					f.write("    - element_info: " + CSVToolkit._format_yaml_value(
						item.get('element_info', '')) + "\n")
					f.write(
						"      find_type: " + CSVToolkit._format_yaml_value(item.get('find_type', '')) + "\n")
					f.write("      info: " + CSVToolkit._format_yaml_value(item.get('info', '')) + "\n")

		# print(f"âœ… YAMLæ–‡ä»¶å·²ç”Ÿæˆ: {yaml_output_path}")

		# æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ï¼Œæ‰“å°æ—¥å¿—è¿‡å¤šï¼Œæš‚æ—¶æ³¨é‡Š
		# print(f"ğŸ“Š è½¬æ¢ç»Ÿè®¡:")
		# print(f"  testinfo: {len(yaml_data['testinfo'])} æ¡")
		# print(f"  testcase: {len(yaml_data['testcase'])} æ¡")
		# print(f"  check: {len(yaml_data['check'])} æ¡")

		# """
		# å¢å¼ºç‰ˆçš„CSVåˆ°YAMLè½¬æ¢ï¼Œæ›´æ™ºèƒ½åœ°è§£ææ•°æ®
		# """
		# # æ™ºèƒ½è¯†åˆ«æ•°æ®ç»“æ„
		# sections = {}
		# current_section = None
		# section_headers = {}
		#
		# # åˆ†æç¬¬ä¸€è¡Œï¼Œæ‰¾å‡ºæ‰€æœ‰section
		# for col_idx, header in enumerate(rows[0]):
		# 	if header and header not in ['Unnamed: 1', 'Unnamed: 2', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6',
		# 	                             'Unnamed: 8', 'Unnamed: 9']:
		# 		current_section = header
		# 		sections[current_section] = []
		# 		section_headers[current_section] = []
		#
		# # æ”¶é›†ç¬¬äºŒè¡Œçš„å­—æ®µå
		# for col_idx, sub_header in enumerate(rows[1]):
		# 	# æ‰¾åˆ°è¿™ä¸ªåˆ—å±äºå“ªä¸ªsection
		# 	for section in sections.keys():
		# 		# ç®€å•åˆ†é…ï¼šæ ¹æ®åˆ—çš„ä½ç½®åˆ†é…
		# 		if section == 'testinfo' and col_idx < 3:
		# 			if sub_header:
		# 				section_headers[section].append(sub_header)
		# 		elif section == 'testcase' and 3 <= col_idx < 7:
		# 			if sub_header:
		# 				section_headers[section].append(sub_header)
		# 		elif section == 'check' and col_idx >= 7:
		# 			if sub_header:
		# 				section_headers[section].append(sub_header)
		#
		# # å¤„ç†æ•°æ®è¡Œ
		# for row_idx in range(2, len(rows)):
		# 	row = rows[row_idx]
		#
		# 	# è·³è¿‡å®Œå…¨ç©ºçš„è¡Œ
		# 	if not any(cell.strip() if cell else False for cell in row):
		# 		continue
		#
		# 	# å¤„ç†testinfo
		# 	if row[0]:  # idä¸ä¸ºç©º
		# 		testinfo_item = {}
		# 		for i, field in enumerate(section_headers['testinfo']):
		# 			if i < len(row) and row[i]:
		# 				testinfo_item[field] = row[i].strip()
		# 		if testinfo_item:
		# 			sections['testinfo'].append(testinfo_item)
		#
		# 	# å¤„ç†testcase
		# 	testcase_item = {}
		# 	for i in range(3, 7):  # testcaseåœ¨3-6åˆ—
		# 		if i < len(row) and row[i]:
		# 			field_idx = i - 3
		# 			if field_idx < len(section_headers['testcase']):
		# 				testcase_item[section_headers['testcase'][field_idx]] = row[i].strip()
		#
		# 	if testcase_item:
		# 		sections['testcase'].append(testcase_item)
		#
		# 	# å¤„ç†check
		# 	check_item = {}
		# 	for i in range(7, min(10, len(row))):  # checkåœ¨7-9åˆ—
		# 		if i < len(row) and row[i]:
		# 			field_idx = i - 7
		# 			if field_idx < len(section_headers['check']):
		# 				check_item[section_headers['check'][field_idx]] = row[i].strip()
		#
		# 	if check_item:
		# 		sections['check'].append(check_item)
		#
		# # å¦‚æœæŒ‡å®šäº†è¾“å‡ºè·¯å¾„ï¼Œå†™å…¥æ–‡ä»¶
		# if yaml_output_path:
		# 	with open(yaml_output_path, 'w', encoding='utf-8') as f:
		# 		yaml.dump(sections, f, allow_unicode=True, default_flow_style=False, sort_keys=False)
		#
		# 	print(f"âœ… YAMLæ–‡ä»¶å·²ç”Ÿæˆ: {yaml_output_path}")

		return yaml_data



# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
	# é¢„è§ˆæ–‡ä»¶
	CSVToolkit.preview_csv('G:/DemoUI-master/testdata/login_data.csv')

	# éªŒè¯æ–‡ä»¶
	result = CSVToolkit.validate_csv('G:/DemoUI-master/testdata/login_data.csv')
	print(f"éªŒè¯ç»“æœ: {'é€šè¿‡' if result['valid'] else 'å¤±è´¥'}")
	if result['issues']:
		print("é—®é¢˜:", result['issues'])

	# è½¬æ¢ç¼–ç ï¼ˆå¦‚æœéœ€è¦ï¼‰
	CSVToolkit.convert_encoding('G:/DemoUI-master/testdata/login_data.csv', 'utf-8-sig')
	yaml_code = CSVToolkit.csv_to_yamldata_code('G:/DemoUI-master/testdata/login_data.csv', 'G:/DemoUI-master/testdata/login_data.yaml')
	print("ç”Ÿæˆçš„YAMLä»£ç å·²ä¿å­˜")

	# è½¬æ¢ç¼–ç ï¼ˆå¦‚æœéœ€è¦ï¼‰
	CSVToolkit.convert_encoding('G:/DemoUI-master/testyaml/login.csv', 'utf-8-sig')
	yaml_code = CSVToolkit.csv_to_yamlelement_code('G:/DemoUI-master/testyaml/login.csv',
	                                        'G:/DemoUI-master/testyaml/login.yaml')
	print("ç”Ÿæˆçš„YAMLä»£ç å·²ä¿å­˜")